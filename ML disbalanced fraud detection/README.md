# Обучение модели для поиска мошеннических транзакций на сильно несбалансированных данных (Precision≈0.92, Recall≈0.8)

## Подготовка данных, undersampling, скалирование. Обучение и проверка модели, кросс-валидация

Данные всего с 492 мошенническими операциями на почти 300тыс. легитимных

Модель *XGBClassifier*, позволяющая работать с весами классов при необходимости  

![image](https://github.com/user-attachments/assets/75533c78-d1a2-4d65-94fe-5e126590c474)

В сравнении с классической *LogisticRegression* из `sklearn.linear_model`

![image](https://github.com/user-attachments/assets/8fe05d87-f192-466b-815e-cb47d887946f)

# Обзор

В `data_manipulating.py` реализован метод для разбиения данных на тренировочную, валидационную и тестовую выборки, с возможностью применить undersampling и последующее скалирование.

В `model.py` реализовано обучение модели с использование кросс валидации для выбора лучших параметров, а так же методы для сбора метрик.

Примерный вывод:  
![image](https://github.com/user-attachments/assets/bb514852-1d56-4d1c-a36b-babbbd38a6bf)

Из-за слишком сильного дизбаланса классов и отличной работы *XGBClassifier* с этим дизбалансом - undersampling с 300 до 100 тысяч почти никак не влияет на результаты


Источник данных:  
[Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data)
